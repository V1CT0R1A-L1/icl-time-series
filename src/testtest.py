import torch
import math
import numpy as np

# âš ï¸ æ³¨æ„ï¼šä½ éœ€è¦ç¡®ä¿ä½ çš„ MultiContextMixtureSampler å’Œ MultiContextMixtureLinear
# å·²ç»ä»ä½ çš„é¡¹ç›®ä¸­æ­£ç¡®å¯¼å…¥åˆ°è¿™é‡Œã€‚

from samplers import MultiContextMixtureSampler 
from tasks import MultiContextMixtureLinear
# å‡è®¾ Sampler å’Œ Task ç±»å·²ç»å®šä¹‰åœ¨å½“å‰ç¯å¢ƒä¸­

def run_pipeline_test():
    """æµ‹è¯• Sampler å’Œ Task æ˜¯å¦æ­£ç¡®åœ°ç”Ÿæˆäº†åºåˆ—å’Œç›®æ ‡å€¼ã€‚"""
    
    # --- 1. å®šä¹‰æµ‹è¯•é…ç½® ---
    N_DIMS = 5
    N_CONTEXTS = 1  # ç®€åŒ–ä¸ºå•ä¸Šä¸‹æ–‡
    CONTEXT_LENGTH = 8
    PREDICT_LENGTH = 1
    B_SIZE = 1
    
    # æœŸæœ›çš„åºåˆ—é•¿åº¦ L: CL + SEP + PRED = 8 + 1 + 1 = 10
    EXPECTED_LENGTH = N_CONTEXTS * CONTEXT_LENGTH + N_CONTEXTS + 1
    # æœŸæœ›çš„é¢„æµ‹ç‚¹ç´¢å¼• I: L - 1 = 9
    EXPECTED_PREDICT_IND = EXPECTED_LENGTH - 1
    
    print(f"--- ğŸš€ è¿è¡Œæ•°æ®ç®¡é“æµ‹è¯• ---")
    print(f"é…ç½®: N_DIMS={N_DIMS}, N_CONTEXTS={N_CONTEXTS}, CL={CONTEXT_LENGTH}")
    print(f"æœŸæœ›åºåˆ—é•¿åº¦ L={EXPECTED_LENGTH}, æœŸæœ›é¢„æµ‹ç´¢å¼• I={EXPECTED_PREDICT_IND}")
    print("-" * 30)

    # --- 2. åˆå§‹åŒ– Sampler å’Œ Task ---
    try:
        sampler = MultiContextMixtureSampler(
            N_DIMS, n_contexts=N_CONTEXTS, n_components=2, 
            context_length=CONTEXT_LENGTH, predict_length=PREDICT_LENGTH
        )
        task = MultiContextMixtureLinear(
            N_DIMS, B_SIZE, n_contexts=N_CONTEXTS, n_components=2,
            context_length=CONTEXT_LENGTH, predict_length=PREDICT_LENGTH, scale=1.0
        )
    except NameError as e:
        print(f"âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ° Sampler æˆ– Task ç±»ã€‚è¯·ç¡®ä¿ç±»å·²å®šä¹‰æˆ–å¯¼å…¥ã€‚è¯¦ç»†: {e}")
        return

    # --- 3. éªŒè¯åºåˆ—ç»“æ„ (Sampler) ---
    structure = sampler.get_sequence_structure()
    
    # æ ¡éªŒé•¿åº¦
    if structure['total_length'] != EXPECTED_LENGTH:
        print(f"âŒ ç»“æ„é”™è¯¯: å®é™…é•¿åº¦ {structure['total_length']} != æœŸæœ›é•¿åº¦ {EXPECTED_LENGTH}")
        return
    
    # æ ¡éªŒé¢„æµ‹ç´¢å¼•
    if structure['predict_inds'][0] != EXPECTED_PREDICT_IND:
        print(f"âŒ ç»“æ„é”™è¯¯: å®é™…é¢„æµ‹ç´¢å¼• {structure['predict_inds'][0]} != æœŸæœ›ç´¢å¼• {EXPECTED_PREDICT_IND}")
        return
        
    # æ ¡éªŒ SEP ç´¢å¼•
    sep_pos = structure['sep_positions']
    if sep_pos[0] != CONTEXT_LENGTH:
        print(f"âŒ ç»“æ„é”™è¯¯: å®é™… SEP ç´¢å¼• {sep_pos[0]} != æœŸæœ›ç´¢å¼• {CONTEXT_LENGTH}")
        return
        
    print(f"âœ… Sampler ç»“æ„æ£€æŸ¥é€šè¿‡ (L={EXPECTED_LENGTH}, I={EXPECTED_PREDICT_IND})")

    # --- 4. é‡‡æ · X (Sampler) ---
    xs = sampler.sample_xs(EXPECTED_LENGTH, B_SIZE)
    
    # æ£€æŸ¥ X çš„ç»´åº¦
    if xs.shape != (B_SIZE, EXPECTED_LENGTH, N_DIMS):
        print(f"âŒ X ç»´åº¦é”™è¯¯: å®é™… {xs.shape} != æœŸæœ› ({B_SIZE}, {EXPECTED_LENGTH}, {N_DIMS})")
        return
        
    # æ£€æŸ¥ SEP Token æ˜¯å¦å½’é›¶ (ç´¢å¼• 8)
    sep_idx = sep_pos[0]
    if torch.any(xs[0, sep_idx] != 0.0):
        print(f"âŒ X å€¼é”™è¯¯: SEP ç´¢å¼• {sep_idx} å¤„çš„ X å€¼ä¸ä¸ºé›¶ã€‚")
        return
        
    # æ£€æŸ¥ Context/Predict X æ˜¯å¦éé›¶ (ç´¢å¼• 0 å’Œ 9)
    if torch.all(xs[0, 0] == 0.0) or torch.all(xs[0, EXPECTED_PREDICT_IND] == 0.0):
        print("âŒ X å€¼é”™è¯¯: Context æˆ– Predict ç´¢å¼•å¤„çš„ X å€¼ä¸ºé›¶ã€‚")
        return
        
    print(f"âœ… Sampler X å€¼æ£€æŸ¥é€šè¿‡ (SEP={sep_idx} ä¸ºé›¶, Context/Predict éé›¶)")

    # --- 5. è®¡ç®— Y (Task) ---
    ys = task.evaluate(xs)
    
    # æ£€æŸ¥ Y çš„ç»´åº¦
    if ys.shape != (B_SIZE, EXPECTED_LENGTH):
        print(f"âŒ Y ç»´åº¦é”™è¯¯: å®é™… {ys.shape} != æœŸæœ› ({B_SIZE}, {EXPECTED_LENGTH})")
        return

    # æ£€æŸ¥ SEP Y å€¼ (ç´¢å¼• 8)
    y_sep = ys[0, sep_idx].item()
    if abs(y_sep) > 1e-6:
        print(f"âŒ Y å€¼é”™è¯¯: SEP ç´¢å¼• {sep_idx} å¤„çš„ Y å€¼ä¸ä¸ºé›¶ ({y_sep:.4f})ã€‚")
        return

    # æ£€æŸ¥ Context Y å€¼ (ç´¢å¼• 0)
    y_context = ys[0, 0].item()
    if abs(y_context) < 1e-3:
        print(f"âŒ Y å€¼é”™è¯¯: Context ç´¢å¼• 0 å¤„çš„ Y å€¼æ¥è¿‘é›¶ ({y_context:.4f})ã€‚")
        return

    # æ£€æŸ¥ Predict Y å€¼ (ç´¢å¼• 9)
    y_predict = ys[0, EXPECTED_PREDICT_IND].item()
    if abs(y_predict) < 1e-3:
        print(f"âŒ Y å€¼é”™è¯¯: Predict ç´¢å¼• {EXPECTED_PREDICT_IND} å¤„çš„ Y å€¼æ¥è¿‘é›¶ ({y_predict:.4f})ã€‚")
        return
        
    # æ£€æŸ¥ Y çš„å°ºåº¦ (æœŸæœ›æ–¹å·® ~1.0)
    y_std = ys[0, :CONTEXT_LENGTH].std().item()
    if not (0.5 < y_std < 2.0):
        print(f"âš ï¸ è­¦å‘Š: Context Y çš„æ ‡å‡†å·® {y_std:.4f} ä¸åœ¨æœŸæœ›èŒƒå›´ (0.5-2.0)ã€‚è¯·æ£€æŸ¥å½’ä¸€åŒ–ã€‚")
        
    print(f"âœ… Task Y å€¼æ£€æŸ¥é€šè¿‡ã€‚")
    print(f"   Context Y (0): {y_context:.4f}")
    print(f"   SEP Y ({sep_idx}): {y_sep:.4f} (å¿…é¡»ä¸ºé›¶)")
    print(f"   Predict Y ({EXPECTED_PREDICT_IND}): {y_predict:.4f} (å¿…é¡»éé›¶)")
    print("-" * 30)
    print("âœ¨ **æ­å–œï¼æ•°æ®ç®¡é“å·²é€šè¿‡æ‰€æœ‰åŸºæœ¬æ£€æŸ¥ã€‚**")
    print("å¦‚æœæ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼Œè¯·å†æ¬¡æ£€æŸ¥ train_step ä¸­çš„ Loss Maskingï¼")

if __name__ == "__main__":
    # åœ¨è¿™é‡Œæ”¾ç½®ä½ çš„ Sampler å’Œ Task ç±»å®šä¹‰ï¼ˆå¦‚æœå®ƒä»¬æ²¡æœ‰è¢«å¯¼å…¥ï¼‰
    # ... [MultiContextMixtureSampler å’Œ MultiContextMixtureLinear çš„ä»£ç ]
    
    run_pipeline_test()