inherit:
  - models/standard.yaml
  - wandb.yaml

model:
  n_dims: 5        # input dimension
  n_positions: 80   # need n_positions//2 >= max length; K=3,C=10,T=6 => 37, so >= 74
  use_pairs_format: true  # one token per (x,y), last token = [x_query; 0]; standard ICL layout, often learns better than interleaved

training:
  task: group_mixture_linear
  data: group_mixture_linear
  task_kwargs:
    n_components: 3             # K (number of components)
    contexts_per_component: 10  # C (final value; curriculum.points drives current C during training)
    target_cluster_context_points: 5  # T (points with y-values in target cluster for inference)
    noise_std: 0.0
    scale: 0.5                # target scale
    normalize_ys: false       # set true to report MSE in normalized space
    # Switch: true = predict ONE position (target query only). false = predict ALL positions.
    predict_target_only: false
    # Switch: false = group into clusters. true = shuffle only context clusters (target cluster stays in order).
    shuffle_context_points: false
  batch_size: 64
  learning_rate: 0.0005   # lower LR so loss can descend to ~0 in noiseless case (0.003 often plateaus at ~0.3)
  lr_warmup_steps: 300    # linear warmup; helps loss descend smoothly in noiseless ICL
  save_every_steps: 1000
  keep_every_steps: 100000   # also saves state_{step}.pt at these steps so you can restore (e.g. copy state_9000.pt -> state.pt)
  train_steps: 20001
  # resume: true = load state.pt when present. resume: false = always start from step 0 (ignore state.pt).
  resume: false
  # Curriculum: ramp difficulty over time. group_mixture_linear uses both.
  # - dims: number of input dimensions used (rest zeroed). Start small, ramp to full.
  # - points: used as contexts_per_component (C) during training. Start with short sequences, ramp to full.
  curriculum:
    dims:
      start: 2
      end: 5
      inc: 1
      interval: 2000
    points:
      start: 5
      end: 10
      inc: 1
      interval: 2000

out_dir: ../models/group_mixture_linear

wandb:
  name: "group_mixture_linear"

test_run: False

